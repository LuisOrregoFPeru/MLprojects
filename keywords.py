import streamlit as st
import PyPDF2
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ------------------------------------------------------------
#  Sugeridor de PalabrasÂ Clave basado en el Tesauro UNESCO
#  ---------------------------------------------------------
#  â€¢ Ingrese un resumen en espaÃ±ol (o cualquier texto breve).
#  â€¢ El sistema propone las 3 voces mÃ¡s prÃ³ximas del Tesauro UNESCO.
#  â€¢ Por defecto carga el PDF "unesco-thesaurus-es.pdf" incluido en
#    el repositorio, pero permite sustituirlo por otro.
# ------------------------------------------------------------

@st.cache_data(show_spinner=False)
def load_thesaurus(pdf_file="unesco-thesaurus-es.pdf"):
    """Extrae un conjunto de tÃ©rminos (en minÃºsculas) del Tesauro PDF."""
    if isinstance(pdf_file, str):
        fp = open(pdf_file, "rb")
        close_needed = True
    else:  #Â UploadedFile de Streamlit
        fp = pdf_file
        close_needed = False

    reader = PyPDF2.PdfReader(fp)
    terms = set()

    for page in reader.pages:
        text = page.extract_text() or ""
        for raw in text.splitlines():
            line = raw.strip()
            #â€¯Filtra numeraciÃ³n u otras lÃ­neas vacÃ­as
            if not line or line.isdigit():
                continue
            #â€¯Suprime prefijos de relaciones (AR:, BT:, UF:, etc.)
            if re.match(r"^(AR|EN|FR|RU|UF|BT|NT|RT|SN|MT)\s*:", line):
                continue
            #â€¯El tÃ©rmino acaba ante un â€˜:â€™ si existe
            term = line.split(":", 1)[0]
            #â€¯SÃ³lo letras y espacios
            term = re.sub(r"[^A-Za-zÃÃ‰ÃÃ“ÃšÃœÃ‘Ã¡Ã©Ã­Ã³ÃºÃ¼Ã± ]", "", term).strip().lower()
            if term:
                terms.add(term)

    if close_needed:
        fp.close()

    return sorted(terms)

@st.cache_data(show_spinner=False)
def prepare_vectorizer(terms):
    """Entrena un TFâ€‘IDF simple sobre la lista de descriptores."""
    vect = TfidfVectorizer(analyzer="word")
    matrix = vect.fit_transform(terms)
    return vect, matrix


def suggest_keywords(summary: str, terms, vect, matrix, k: int = 3):
    """Devuelve las k voces del Tesauro mÃ¡s parecidas al resumen."""
    vec = vect.transform([summary])
    sims = cosine_similarity(vec, matrix).flatten()
    top = sims.argsort()[-k:][::-1]
    return [terms[i] for i in top if sims[i] > 0]


def main():
    st.set_page_config(page_title="Sugeridor Tesauro UNESCO", page_icon="ðŸ“š")
    st.title("ðŸ“š Propuesta automÃ¡tica de palabrasÂ clave (TesauroÂ UNESCO)")
    st.write("Suba un resumen y obtenga las tres voces mÃ¡s afines del Tesauro UNESCO en espaÃ±ol.")

    #â€¯Carga (opcional) de un PDF distinto
    pdf_up = st.file_uploader("Tesauro PDF (opcional)", type=["pdf"], help="Si no selecciona nada se usarÃ¡ el PDF del repositorio.")
    pdf_source = pdf_up if pdf_up is not None else "unesco-thesaurus-es.pdf"

    #â€¯Prepara el Tesauro y el vectorizador
    with st.spinner("Analizando tesauro ..."):
        terms = load_thesaurus(pdf_source)
        vect, matrix = prepare_vectorizer(terms)

    text = st.text_area("Pegue su resumen aquÃ­:", height=220)
    if st.button("ðŸ”‘ Proponer palabrasÂ clave") and text.strip():
        kw = suggest_keywords(text, terms, vect, matrix)
        if kw:
            st.success("Palabras clave sugeridas:")
            for t in kw:
                st.write(f"â€¢ {t.capitalize()}")
        else:
            st.info("No se hallaron coincidencias significativas. Intente reformular el texto.")

    st.caption("Â©Â UNESCO â€“ Tesauro original.Â |Â App creada con Streamlit.")


if __name__ == "__main__":
    main()
